# è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½å®æ–½æ–¹æ¡ˆ

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

åœ¨éŸ³é¢‘ä¸Šä¼ åè‡ªåŠ¨è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ï¼Œåœ¨ç”»å¸ƒèŠ‚ç‚¹ä¸­å±•ç¤ºè½¬å½•å†…å®¹ï¼Œæ”¯æŒæ–‡æœ¬æœç´¢å’ŒAIé—®ç­”ã€‚

## ğŸ”§ æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ1: OpenAI Whisper API (æ¨è)
```typescript
// åç«¯APIè°ƒç”¨ç¤ºä¾‹
const transcription = await openai.audio.transcriptions.create({
  file: audioFile,
  model: "whisper-1",
  language: "zh", // è‡ªåŠ¨æ£€æµ‹æˆ–æŒ‡å®šè¯­è¨€
  response_format: "verbose_json", // åŒ…å«æ—¶é—´æˆ³ä¿¡æ¯
  timestamp_granularities: ["word"] // è¯çº§åˆ«æ—¶é—´æˆ³
});
```

**ä¼˜åŠ¿**ï¼š
- âœ… å‡†ç¡®åº¦é«˜ (90%+)
- âœ… ä¸­è‹±æ–‡æ”¯æŒä¼˜ç§€
- âœ… ä¸ç°æœ‰OpenAIé›†æˆä¸€è‡´
- âœ… æ”¯æŒæ—¶é—´æˆ³è¾“å‡º
- âœ… APIç®€å•ç¨³å®š

**æˆæœ¬**: $0.006/åˆ†é’Ÿ

### æ–¹æ¡ˆ2: Azure Speech Services
```typescript
// Azureé…ç½®ç¤ºä¾‹
const speechConfig = SpeechConfig.fromSubscription(key, region);
speechConfig.speechRecognitionLanguage = "zh-CN";
const recognizer = SpeechRecognizer.FromConfig(speechConfig);
```

**ä¼˜åŠ¿**ï¼š
- âœ… ä¼ä¸šçº§å¯é æ€§
- âœ… æ”¯æŒå®æ—¶è½¬å½•
- âœ… è¯¦ç»†çš„ç½®ä¿¡åº¦åˆ†æ•°

**åŠ£åŠ¿**ï¼š
- âŒ é›†æˆå¤æ‚åº¦è¾ƒé«˜
- âŒ æˆæœ¬ç›¸å¯¹è¾ƒé«˜

### æ–¹æ¡ˆ3: æœ¬åœ°Whisperæ¨¡å‹
```python
# æœ¬åœ°éƒ¨ç½²ç¤ºä¾‹
import whisper
model = whisper.load_model("large-v3")
result = model.transcribe("audio.mp3", language="zh")
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ•°æ®éšç§æœ€ä½³
- âœ… é•¿æœŸæˆæœ¬ä½

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦GPUèµ„æº
- âŒ éƒ¨ç½²è¿ç»´å¤æ‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æµç¨‹
```
ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘ â†’ æ–‡ä»¶å­˜å‚¨ â†’ åå°è½¬å½•ä»»åŠ¡ â†’ å­˜å‚¨è½¬å½•ç»“æœ â†’ å‰ç«¯å®æ—¶æ›´æ–°
```

### åç«¯å®ç°

#### 1. æ·»åŠ è½¬å½•æœåŠ¡
```typescript
// apps/api/src/modules/transcription/transcription.service.ts
@Injectable()
export class TranscriptionService {
  async transcribeAudio(resourceId: string, audioFile: Buffer): Promise<TranscriptionResult> {
    try {
      // è°ƒç”¨Whisper API
      const transcription = await this.openai.audio.transcriptions.create({
        file: new File([audioFile], 'audio.mp3'),
        model: 'whisper-1',
        language: 'zh',
        response_format: 'verbose_json',
        timestamp_granularities: ['word']
      });

      // ä¿å­˜è½¬å½•ç»“æœ
      return await this.saveTranscription(resourceId, transcription);
    } catch (error) {
      // é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
      throw new TranscriptionError(`è½¬å½•å¤±è´¥: ${error.message}`);
    }
  }
}
```

#### 2. æ‰©å±•èµ„æºæ¨¡å‹
```sql
-- æ‰©å±•resourceè¡¨
ALTER TABLE resource ADD COLUMN transcription_text TEXT;
ALTER TABLE resource ADD COLUMN transcription_status VARCHAR(20) DEFAULT 'pending';
ALTER TABLE resource ADD COLUMN audio_duration INTEGER;
ALTER TABLE resource ADD COLUMN transcription_confidence FLOAT;

-- æ–°å¢è½¬å½•è¯¦æƒ…è¡¨
CREATE TABLE audio_transcription (
  id SERIAL PRIMARY KEY,
  resource_id VARCHAR(255) NOT NULL,
  transcription_text TEXT NOT NULL,
  segments JSONB, -- åˆ†æ®µä¿¡æ¯å’Œæ—¶é—´æˆ³
  language VARCHAR(10),
  confidence_score FLOAT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 3. å¼‚æ­¥å¤„ç†é˜Ÿåˆ—
```typescript
// è½¬å½•ä»»åŠ¡é˜Ÿåˆ—
@Processor('transcription')
export class TranscriptionProcessor {
  @Process('transcribe-audio')
  async handleTranscription(job: Job<TranscriptionJobData>) {
    const { resourceId, storageKey } = job.data;
    
    // è·å–éŸ³é¢‘æ–‡ä»¶
    const audioBuffer = await this.oss.getObject(storageKey);
    
    // æ‰§è¡Œè½¬å½•
    const result = await this.transcriptionService.transcribeAudio(resourceId, audioBuffer);
    
    // æ›´æ–°èµ„æºçŠ¶æ€
    await this.updateResourceTranscription(resourceId, result);
    
    // é€šçŸ¥å‰ç«¯æ›´æ–°
    this.eventEmitter.emit('transcription.completed', { resourceId, result });
  }
}
```

### å‰ç«¯å®ç°

#### 1. éŸ³é¢‘èŠ‚ç‚¹ç»„ä»¶å¢å¼º
```typescript
// packages/ai-workspace-common/src/components/canvas/nodes/audio.tsx
export const AudioNode = ({ data }: AudioNodeProps) => {
  const [transcriptionStatus, setTranscriptionStatus] = useState('pending');
  const [transcriptionText, setTranscriptionText] = useState('');
  const [isExpanded, setIsExpanded] = useState(false);

  return (
    <div className="audio-node">
      {/* éŸ³é¢‘æ’­æ”¾æ§ä»¶ */}
      <AudioPlayer src={data.audioUrl} />
      
      {/* è½¬å½•çŠ¶æ€å’Œç»“æœ */}
      <div className="transcription-section">
        {transcriptionStatus === 'pending' && (
          <div className="flex items-center gap-2">
            <Spin size="small" />
            <span>æ­£åœ¨è½¬å½•ä¸­...</span>
          </div>
        )}
        
        {transcriptionStatus === 'completed' && (
          <div className="transcription-content">
            <div 
              className="transcription-preview cursor-pointer"
              onClick={() => setIsExpanded(!isExpanded)}
            >
              <span className="text-sm text-gray-600">è½¬å½•æ–‡æœ¬ï¼š</span>
              <span className="ml-2">{transcriptionText.slice(0, 50)}...</span>
            </div>
            
            {isExpanded && (
              <div className="transcription-full mt-2 p-3 bg-gray-50 rounded">
                <p className="text-sm whitespace-pre-wrap">{transcriptionText}</p>
                {/* ç¼–è¾‘å’Œå¤åˆ¶åŠŸèƒ½ */}
                <div className="mt-2 flex gap-2">
                  <Button size="small" onClick={handleCopyText}>å¤åˆ¶</Button>
                  <Button size="small" onClick={handleEditText}>ç¼–è¾‘</Button>
                </div>
              </div>
            )}
          </div>
        )}
        
        {transcriptionStatus === 'failed' && (
          <div className="flex items-center gap-2">
            <span className="text-red-500">è½¬å½•å¤±è´¥</span>
            <Button size="small" onClick={handleRetryTranscription}>é‡è¯•</Button>
          </div>
        )}
      </div>
    </div>
  );
};
```

#### 2. å®æ—¶çŠ¶æ€æ›´æ–°
```typescript
// WebSocketæˆ–Server-Sent Eventsç›‘å¬è½¬å½•çŠ¶æ€
useEffect(() => {
  const eventSource = new EventSource(`/api/v1/transcription/status/${resourceId}`);
  
  eventSource.onmessage = (event) => {
    const data = JSON.parse(event.data);
    setTranscriptionStatus(data.status);
    if (data.status === 'completed') {
      setTranscriptionText(data.transcriptionText);
    }
  };

  return () => eventSource.close();
}, [resourceId]);
```

## ğŸ¨ UI/UX è®¾è®¡

### éŸ³é¢‘èŠ‚ç‚¹å¸ƒå±€
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸµ éŸ³é¢‘æ–‡ä»¶å.mp3               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¶ï¸ â”â”â”â”â”â”â”â”â”â” 03:45 ğŸ”Š        â”‚ â† æ’­æ”¾æ§ä»¶
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“ è½¬å½•æ–‡æœ¬ï¼šè¿™æ˜¯ä¸€æ®µå…³äº...      â”‚ â† å¯ç‚¹å‡»å±•å¼€
â”‚    [å±•å¼€] [å¤åˆ¶] [ç¼–è¾‘]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è½¬å½•çŠ¶æ€æŒ‡ç¤º
- ğŸ”„ è½¬å½•ä¸­ - æ˜¾ç¤ºè¿›åº¦åŠ¨ç”»
- âœ… è½¬å½•å®Œæˆ - æ˜¾ç¤ºæ–‡æœ¬é¢„è§ˆ
- âŒ è½¬å½•å¤±è´¥ - æ˜¾ç¤ºé‡è¯•æŒ‰é’®
- âœï¸ æ‰‹åŠ¨ç¼–è¾‘ - å…è®¸ç”¨æˆ·ä¿®æ­£æ–‡æœ¬

## ğŸ’° æˆæœ¬æ§åˆ¶ç­–ç•¥

### 1. åˆ†å±‚æ”¶è´¹
```typescript
const TRANSCRIPTION_LIMITS = {
  free: { minutesPerMonth: 10, maxFileSize: '25MB' },
  pro: { minutesPerMonth: 300, maxFileSize: '100MB' },
  enterprise: { minutesPerMonth: -1, maxFileSize: '500MB' }
};
```

### 2. æ™ºèƒ½ä¼˜åŒ–
- éŸ³é¢‘é¢„å¤„ç†ï¼ˆé™å™ªã€æ ¼å¼è½¬æ¢ï¼‰
- åˆ†æ®µè½¬å½•ï¼ˆå‡å°‘é‡å¤æˆæœ¬ï¼‰
- ç¼“å­˜æœºåˆ¶ï¼ˆé¿å…é‡å¤è½¬å½•ï¼‰

### 3. ç”¨æˆ·æ§åˆ¶
- æ‰‹åŠ¨è§¦å‘è½¬å½•é€‰é¡¹
- è½¬å½•å‰é¢„ä¼°æˆæœ¬æç¤º
- æ‰¹é‡å¤„ç†ä¼˜åŒ–

## ğŸ” æœç´¢é›†æˆ

### å…¨æ–‡æœç´¢å¢å¼º
```typescript
// å°†è½¬å½•æ–‡æœ¬åŠ å…¥æœç´¢ç´¢å¼•
await this.fts.upsertDocument(user, 'resource', {
  id: resource.resourceId,
  content: transcriptionText, // è½¬å½•æ–‡æœ¬ä½œä¸ºå¯æœç´¢å†…å®¹
  metadata: {
    resourceType: 'audio',
    duration: audioDuration,
    language: detectedLanguage
  }
});
```

### å‘é‡æœç´¢æ”¯æŒ
```typescript
// ä¸ºè½¬å½•æ–‡æœ¬ç”Ÿæˆembedding
const embedding = await this.embeddingService.createEmbedding(transcriptionText);
await this.vectorStore.upsert({
  id: resourceId,
  values: embedding,
  metadata: { type: 'audio-transcription', text: transcriptionText }
});
```

## ğŸ“Š ç›‘æ§å’Œåˆ†æ

### è½¬å½•è´¨é‡ç›‘æ§
- è½¬å½•æˆåŠŸç‡ç»Ÿè®¡
- å¹³å‡è½¬å½•æ—¶é—´
- ç”¨æˆ·æ»¡æ„åº¦åé¦ˆ
- é”™è¯¯ç±»å‹åˆ†æ

### æˆæœ¬åˆ†æ
- æ¯æœˆè½¬å½•åˆ†é’Ÿæ•°
- å¹³å‡æ¯ç”¨æˆ·æˆæœ¬
- è½¬å½•å‡†ç¡®åº¦vsæˆæœ¬å¯¹æ¯”

## ğŸš€ å®æ–½è®¡åˆ’

### Phase 2A: åŸºç¡€è½¬å½• (2å‘¨)
- [x] åŸºç¡€éŸ³é¢‘ä¸Šä¼  (å·²å®Œæˆ)
- [ ] é›†æˆWhisper API
- [ ] åç«¯è½¬å½•æœåŠ¡
- [ ] åŸºç¡€å‰ç«¯å±•ç¤º

### Phase 2B: å¢å¼ºåŠŸèƒ½ (1å‘¨)
- [ ] å®æ—¶çŠ¶æ€æ›´æ–°
- [ ] è½¬å½•æ–‡æœ¬ç¼–è¾‘
- [ ] æœç´¢ç´¢å¼•é›†æˆ

### Phase 2C: ä¼˜åŒ–å’Œç›‘æ§ (1å‘¨)
- [ ] æˆæœ¬æ§åˆ¶æœºåˆ¶
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] ç›‘æ§é¢æ¿

## ğŸ”’ å®‰å…¨å’Œéšç§

### æ•°æ®ä¿æŠ¤
- éŸ³é¢‘æ–‡ä»¶åŠ å¯†å­˜å‚¨
- è½¬å½•æ–‡æœ¬è®¿é—®æ§åˆ¶
- å®šæœŸæ•°æ®æ¸…ç†æœºåˆ¶

### åˆè§„è€ƒè™‘
- ç”¨æˆ·æˆæƒç¡®è®¤
- æ•°æ®å¤„ç†é€æ˜åº¦
- ç¬¦åˆGDPRç­‰æ³•è§„è¦æ±‚ 