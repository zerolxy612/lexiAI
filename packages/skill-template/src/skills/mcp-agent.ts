import { END, START, StateGraph, StateGraphArgs } from '@langchain/langgraph';
import { z } from 'zod';
import { BaseSkill, BaseSkillState, baseStateGraphArgs, SkillRunnableConfig } from '../base';
import { Icon, SkillInvocationConfig, SkillTemplateConfigDefinition } from '@refly/openapi-schema';

// Import MCP modules
import { AIMessage, BaseMessage } from '@langchain/core/messages';
import { Runnable } from '@langchain/core/runnables';
import { GraphState } from '../scheduler/types';
import { prepareContext } from '../scheduler/utils/context';
import { buildFinalRequestMessages } from '../scheduler/utils/message';
import { processQuery } from '../scheduler/utils/queryProcessor';
import {
  ChunkCallbackData,
  MCPServer,
  MCPTool,
  Message,
  MessageRole,
  MCPToolResponse,
} from '../mcp/core/types';
import { MCPAssistant } from '../mcp/core/MCPAssistant';
import { safeStringifyJSON } from '@refly/utils';
import { IContext } from '../scheduler/types';

/**
 * Extended state for MCP Connector skill
 */
interface MCPAgentState extends BaseSkillState {
  mcpActionResult?: Message[];
}

/**
 * MCP Connector Skill
 * Connects to Model Context Protocol servers and makes intelligent decisions
 * about when and how to use their capabilities to solve user queries.
 * Uses MCPAssistant to manage interactions with MCP servers.
 */
export class MCPAgent extends BaseSkill {
  name = 'MCPAgent';

  icon: Icon = { type: 'emoji', value: 'ğŸ”Œ' };

  displayName = {
    en: 'MCP Agent',
    'zh-CN': 'MCP Agent',
  };

  description =
    'Connect to MCP servers and intelligently leverage their capabilities to solve user queries';

  // MCPAssistant instances cache - store assistants by session ID
  private mcpAssistants: Record<string, MCPAssistant> = {};

  // Server configurations cache
  private serverConfigs: Record<string, MCPServer> = {};

  // Configuration schema for the skill
  configSchema: SkillTemplateConfigDefinition = {
    items: [
      {
        key: 'mcpServerUrls',
        inputMode: 'inputTextArea',
        defaultValue: '',
        labelDict: {
          en: 'MCP Server URLs',
          'zh-CN': 'MCPæœåŠ¡å™¨åœ°å€',
        },
        descriptionDict: {
          en: 'Comma-separated list of MCP server URLs',
          'zh-CN': 'ä»¥é€—å·åˆ†éš”çš„MCPæœåŠ¡å™¨URLåˆ—è¡¨',
        },
      },
      {
        key: 'autoConnect',
        inputMode: 'switch',
        defaultValue: true,
        labelDict: {
          en: 'Auto Connect',
          'zh-CN': 'è‡ªåŠ¨è¿æ¥',
        },
        descriptionDict: {
          en: 'Automatically connect to MCP servers on startup',
          'zh-CN': 'å¯åŠ¨æ—¶è‡ªåŠ¨è¿æ¥åˆ°MCPæœåŠ¡å™¨',
        },
      },
      {
        key: 'modelTemperature',
        inputMode: 'inputNumber',
        defaultValue: 0.2,
        labelDict: {
          en: 'Model Temperature',
          'zh-CN': 'æ¨¡å‹æ¸©åº¦',
        },
        descriptionDict: {
          en: 'Temperature for the model when making MCP decisions (0-1)',
          'zh-CN': 'åœ¨è¿›è¡ŒMCPå†³ç­–æ—¶æ¨¡å‹çš„æ¸©åº¦å€¼ï¼ˆ0-1ï¼‰',
        },
        inputProps: {
          min: 0,
          max: 1,
          step: 0.1,
        },
      },
    ],
  };

  // Invocation configuration
  invocationConfig: SkillInvocationConfig = {};

  // Schema definition for input
  schema = z.object({
    query: z.string().optional().describe('User query for MCP interaction'),
    images: z.array(z.string()).optional().describe('Images that might be relevant'),
  });

  // State graph definition with additional mcpActionResult channel
  graphState: StateGraphArgs<MCPAgentState>['channels'] = {
    ...baseStateGraphArgs,
    mcpActionResult: {
      reducer: (_left, right) => right,
      default: () => undefined,
    },
  };

  /**
   * Create a new MCPAssistant or get an existing one
   * @param sessionId Unique session identifier
   * @param config Skill configuration
   * @returns MCPAssistant instance
   */
  private getOrCreateAssistant(sessionId: string, config: SkillRunnableConfig): MCPAssistant {
    // Check if we already have an assistant for this session
    if (this.mcpAssistants[sessionId]) {
      return this.mcpAssistants[sessionId];
    }

    // Create a new assistant
    const assistant = new MCPAssistant({
      autoInjectTools: true,
      modelProvider: (messages) => this.callModel(messages, config),
      onChunk: (data) => this.handleChunk(data, config),
    });

    // Cache the assistant
    this.mcpAssistants[sessionId] = assistant;

    return assistant;
  }

  /**
   * Call the model with messages
   * @param messages Messages to send to the model
   * @param config Skill configuration
   * @returns Model response text
   */
  private async callModel(messages: Message[], config: SkillRunnableConfig): Promise<string> {
    // Convert MCPAssistant messages to BaseMessage format
    const baseMessages = messages.map((msg) => {
      // Map roles
      const roleMap: Record<MessageRole, string> = {
        [MessageRole.SYSTEM]: 'system',
        [MessageRole.USER]: 'user',
        [MessageRole.ASSISTANT]: 'assistant',
      };

      return {
        role: roleMap[msg.role],
        content: msg.content,
      };
    });

    // Get temperature setting
    const temperature = (config.configurable.tplConfig?.modelTemperature?.value as number) || 0.2;

    // Call model
    const model = this.engine.chatModel({ temperature });
    const response = await model.invoke(baseMessages, {
      ...config,
      metadata: {
        ...config.metadata,
        ...config.configurable.currentSkill,
      },
    });

    // Return response content
    return typeof response.content === 'string'
      ? response.content
      : JSON.stringify(response.content);
  }

  /**
   * Handle chunks from MCPAssistant
   * @param data Chunk data
   * @param config Skill configuration
   */
  private handleChunk(data: ChunkCallbackData, config: SkillRunnableConfig): void {
    // Handle text chunks for streaming
    // if (data.text) {
    //   this.emitEvent(
    //     {
    //       content: data.text,
    //       event: 'stream',
    //     },
    //     config,
    //   );
    // }

    // Handle tool response chunks
    if (data.mcpToolResponse) {
      this.handleToolResponses(data.mcpToolResponse, config);
    }
  }

  messageIndex = 0;

  /**
   * Process tool responses and emit structured data
   * @param toolResponses Array of tool response objects
   * @param config Skill configuration
   */
  private handleToolResponses(toolResponses: MCPToolResponse[], config: SkillRunnableConfig): void {
    // æ”¶é›†ä¸åŒçŠ¶æ€çš„å·¥å…·
    const executing = toolResponses.filter((tool) => tool.status === 'invoking');
    const completed = toolResponses.filter((tool) => tool.status === 'done');
    const errors = toolResponses.filter((tool) => tool.status === 'error');

    // æ‰¹é‡å¤„ç†å·¥å…·çŠ¶æ€å˜åŒ–ï¼Œå‡å°‘äº‹ä»¶å‘é€æ¬¡æ•°
    if (executing.length > 0 || completed.length > 0 || errors.length > 0) {
      // æ„å»ºå·¥å…·çŠ¶æ€å˜åŒ–æ‘˜è¦

      if (completed.length > 0) {
        for (const t of completed) {
          // Set initial step

          config.metadata.step = { name: `${t.tool.name}-${this.messageIndex++}` };

          this.emitEvent(
            {
              event: 'log',
              log: {
                key: 'mcpCallingFinish',
                titleArgs: {
                  ...t.tool,
                  status: t.status,
                },
                descriptionArgs: {
                  ...t.tool,
                  status: t.status,

                  json: { params: t.tool.inputSchema, response: t.response },
                },
                ...{ status: 'finish' },
              },
            },
            config,
          );
        }
      }

      if (errors.length > 0) {
        for (const t of errors) {
          // Set initial step
          config.metadata.step = { name: `${t.tool.name}-${this.messageIndex++}` };

          this.emitEvent(
            {
              event: 'log',
              log: {
                key: 'mcpCallingError',
                titleArgs: {
                  ...t.tool,
                  status: t.status,
                },
                descriptionArgs: {
                  ...t.tool,
                  status: t.status,
                  json: { params: t.tool.inputSchema, response: t.response },
                },
                ...{ status: 'error' },
              },
            },
            config,
          );
        }
      }
    }

    // è®°å½•å·¥å…·é”™è¯¯åˆ°æ—¥å¿—ï¼ˆä»ç„¶ä¿ç•™ï¼Œå› ä¸ºé”™è¯¯ä¿¡æ¯å¯¹æ’æŸ¥é—®é¢˜å¾ˆé‡è¦ï¼‰
    for (const tool of errors) {
      const errorMessage = tool.response?.content[0]?.text || 'Unknown error';
      this.engine.logger.error(`Tool ${tool.tool.name} error: ${errorMessage}`);
    }
  }

  /**
   * Build server configurations from URLs
   * @param serverUrls Array of server URLs
   * @returns Array of server configurations
   */
  private buildServerConfigs(serverUrls: string[]): MCPServer[] {
    return serverUrls.map((url, index) => {
      // Check if we already have a configuration for this URL
      if (this.serverConfigs[url]) {
        return this.serverConfigs[url];
      }

      // Create a new configuration
      const config: MCPServer = {
        id: `server-${index}`,
        name: `MCP Server ${index + 1}`,
        description: `MCP server at ${url}`,
        type: url.includes('/sse') ? 'sse' : 'streamableHttp',
        baseUrl: url,
        isActive: true,
      };

      // Cache the configuration
      this.serverConfigs[url] = config;

      return config;
    });
  }

  /**
   * Add servers to MCPAssistant
   * @param assistant MCPAssistant instance
   * @param serverConfigs Array of server configurations
   * @param config Skill configuration
   * @returns Connection results
   */
  private async addServersToAssistant(
    assistant: MCPAssistant,
    serverConfigs: MCPServer[],
    config: SkillRunnableConfig,
  ): Promise<{
    success: boolean;
    connectedServers: string[];
    failedServers: string[];
    loadedTools: MCPTool[];
  }> {
    const connectedServers: string[] = [];
    const failedServers: string[] = [];
    const loadedTools: MCPTool[] = [];

    // åªå‘é€ä¸€ä¸ªè¿æ¥å°è¯•äº‹ä»¶ï¼Œç²¾ç®€æ—¥å¿—
    if (serverConfigs.length > 0) {
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'connecting_mcp_servers',
            titleArgs: {
              count: serverConfigs.length,
            },
          },
        },
        config,
      );
    }

    // Connect to each server
    for (const serverConfig of serverConfigs) {
      try {
        const tools = await assistant.addServer(serverConfig);
        connectedServers.push(serverConfig.baseUrl || serverConfig.id);
        loadedTools.push(...tools);

        this.engine.logger.log(
          `Connected to MCP server: ${serverConfig.baseUrl || serverConfig.id}`,
        );

        // ä¸å†ä¸ºæ¯ä¸ªæœåŠ¡å™¨å•ç‹¬å‘é€è¿æ¥æˆåŠŸäº‹ä»¶
      } catch (error) {
        failedServers.push(serverConfig.baseUrl || serverConfig.id);
        this.engine.logger.error(
          `Failed to connect to MCP server ${serverConfig.baseUrl || serverConfig.id}: ${error}`,
        );
        // ä¸å†ä¸ºæ¯ä¸ªå¤±è´¥çš„æœåŠ¡å™¨å•ç‹¬å‘é€äº‹ä»¶
      }
    }

    // åªå‘é€ä¸€æ¬¡æ±‡æ€»äº‹ä»¶ï¼ŒåŒ…å«æ‰€æœ‰è¿æ¥ç»“æœ
    this.emitEvent(
      {
        event: 'log',
        log: {
          key: 'mcp_connection_summary',
          titleArgs: {
            total: serverConfigs.length,
            connected: connectedServers.length,
            failed: failedServers.length,
          },
          descriptionArgs: {
            totalTools: loadedTools.length,
            failedServers: failedServers.join(', '),
          },
        },
      },
      config,
    );

    return {
      success: connectedServers.length > 0,
      connectedServers,
      failedServers,
      loadedTools,
    };
  }

  /**
   * Clean up MCPAssistant instances and connections
   */
  cleanupSessions(): void {
    // Close all assistants
    for (const [sessionId, assistant] of Object.entries(this.mcpAssistants)) {
      try {
        assistant.close().catch((error) => {
          this.engine.logger.warn(`Failed to close MCPAssistant for ${sessionId}: ${error}`);
        });

        delete this.mcpAssistants[sessionId];
      } catch (error) {
        this.engine.logger.warn(`Error cleaning up MCPAssistant for ${sessionId}: ${error}`);
      }
    }

    // Clear caches
    this.mcpAssistants = {};
  }

  /**
   * Main handler method for the MCP Connector skill
   * @param state Graph state
   * @param config Skill configuration
   * @returns Updated graph state
   */
  callMCPAgent = async (
    state: GraphState,
    config: SkillRunnableConfig,
  ): Promise<Partial<MCPAgentState>> => {
    const { messages = [], images = [] } = state;
    const { tplConfig, project } = config.configurable;

    // Extract customInstructions from project if available
    const customInstructions = project?.customInstructions;

    // Get configuration values
    const mcpServersString = tplConfig?.mcpServerUrls?.value as string;
    const serverUrls = mcpServersString
      ? mcpServersString
          .split(',')
          .map((url) => url.trim())
          .filter((url) => url.length > 0)
      : [];

    const autoConnect = tplConfig?.autoConnect?.value !== false;

    // Generate a session ID for this request
    const sessionId = `session-${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;

    // Set initial step
    config.metadata.step = { name: 'analyzeQuery' };

    // Process the query
    const { query, optimizedQuery, usedChatHistory, mentionedContext, remainingTokens } =
      await processQuery({
        config,
        ctxThis: this,
        state,
      });

    // ç®€åŒ–queryå¤„ç†äº‹ä»¶ï¼Œåªåœ¨æœ‰ä¼˜åŒ–æ—¶æ‰å‘é€äº‹ä»¶
    if (optimizedQuery && optimizedQuery !== query) {
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'query_processed',
            titleArgs: {
              original: query.substring(0, 50) + (query.length > 50 ? '...' : ''),
              optimized:
                optimizedQuery.substring(0, 50) + (optimizedQuery.length > 50 ? '...' : ''),
            },
          },
        },
        config,
      );
    }

    // If no servers or auto-connect disabled, answer directly
    if (!autoConnect || serverUrls.length === 0) {
      // ç®€åŒ–è¿™é‡Œçš„äº‹ä»¶ï¼Œä½¿ç”¨æ›´ç®€æ´çš„å½¢å¼
      this.engine.logger.log(
        `Using direct answer mode: ${!autoConnect ? 'auto-connect disabled' : 'no servers configured'}`,
      );

      return this.handleDirectAnswer(
        query,
        optimizedQuery,
        usedChatHistory,
        mentionedContext,
        remainingTokens,
        images,
        messages,
        config,
        customInstructions,
      );
    }

    // Create MCPAssistant and add servers
    const assistant = this.getOrCreateAssistant(sessionId, config);

    // Build server configurations
    const serverConfigs = this.buildServerConfigs(serverUrls);

    // Connect to servers
    const connectionResult = await this.addServersToAssistant(assistant, serverConfigs, config);

    // If connection failed, answer directly
    if (!connectionResult.success) {
      this.engine.logger.warn('No MCP servers connected, falling back to direct answer');

      return this.handleDirectAnswer(
        query,
        optimizedQuery,
        usedChatHistory,
        mentionedContext,
        remainingTokens,
        images,
        messages,
        config,
        customInstructions,
      );
    }

    try {
      // Set MCP processing step
      config.metadata.step = { name: 'processMCPQuery' };

      // ç²¾ç®€å¤„ç†æŸ¥è¯¢äº‹ä»¶
      this.engine.logger.log(`Processing query with MCP: ${optimizedQuery || query}`);

      config.metadata.step = { name: 'mcpAssistantModelCalling' };

      // Run the assistant with the query
      const assistantResponse = await assistant.run(query);

      // Get all messages for context
      const mcpActionResult = assistant.getMessages();

      // ç®€åŒ–MCPç»“æœäº‹ä»¶
      this.engine.logger.log(
        `MCP execution complete: ${mcpActionResult.length} messages generated`,
      );

      // Create response message
      const responseMessage = new AIMessage({ content: assistantResponse });

      return {
        messages: [responseMessage],
        mcpActionResult,
      };
    } catch (error) {
      // Log error
      this.engine.logger.error(`Error in MCPAssistant processing: ${error}`);

      // ç®€åŒ–é”™è¯¯äº‹ä»¶
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'mcp_processing_error',
            titleArgs: {
              error: String(error),
            },
          },
        },
        config,
      );

      // Fall back to direct answer
      return this.handleDirectAnswer(
        query,
        optimizedQuery,
        usedChatHistory,
        mentionedContext,
        remainingTokens,
        images,
        messages,
        config,
        customInstructions,
      );
    } finally {
      // Clean up the assistant after use
      try {
        await assistant.close();
        delete this.mcpAssistants[sessionId];
      } catch (closeError) {
        this.engine.logger.warn(`Error closing MCPAssistant: ${closeError}`);
      }
    }
  };

  /**
   * Handle direct answering without MCP
   * @param query Original query
   * @param optimizedQuery Optimized query
   * @param usedChatHistory Used chat history
   * @param mentionedContext Mentioned context
   * @param remainingTokens Remaining tokens
   * @param images Images
   * @param messages Messages
   * @param config Skill configuration
   * @param customInstructions Custom instructions from project
   * @returns Updated graph state
   */
  private async handleDirectAnswer(
    query: string,
    optimizedQuery: string,
    usedChatHistory: BaseMessage[],
    mentionedContext: IContext,
    remainingTokens: number,
    images: string[],
    messages: BaseMessage[],
    config: SkillRunnableConfig,
    customInstructions?: string,
  ): Promise<Partial<MCPAgentState>> {
    const { locale = 'en' } = config.configurable;

    // Prepare context for direct answering
    config.metadata.step = { name: 'prepareContext' };

    const { contextStr, sources } = await prepareContext(
      {
        query: optimizedQuery,
        mentionedContext,
        maxTokens: remainingTokens,
        enableMentionedContext: true,
      },
      {
        config,
        ctxThis: this,
        state: { query, images, messages: [] },
        tplConfig: config.configurable.tplConfig,
      },
    );

    // ç®€åŒ–ä¸Šä¸‹æ–‡æºäº‹ä»¶ï¼Œåªåœ¨æ‰¾åˆ°æºä¸”æœ‰ä¸Šä¸‹æ–‡æ—¶æ‰å‘é€
    if (sources?.length > 0 && contextStr) {
      this.engine.logger.log(
        `Found ${sources.length} context sources with ${contextStr.length} characters`,
      );
    }

    // Use simple module for direct answering
    const module = {
      buildSystemPrompt: () =>
        'You are a helpful assistant. Answer the user query based on your knowledge and the provided context if any.',
      buildContextUserPrompt: (context: string) => context,
      buildUserPrompt: ({ originalQuery }: { originalQuery: string }) => originalQuery,
    };

    // Set answer generation step
    config.metadata.step = { name: 'generateDirectAnswer' };

    // Build request messages
    const requestMessages = buildFinalRequestMessages({
      module,
      locale,
      chatHistory: usedChatHistory,
      messages,
      needPrepareContext: !!contextStr,
      context: contextStr,
      images,
      originalQuery: query,
      optimizedQuery,
      modelInfo: config?.configurable?.modelInfo,
      customInstructions,
    });

    // Call model directly with lower temperature for direct answers
    const model = this.engine.chatModel({ temperature: 0.1 });
    const responseMessage = await model.invoke(requestMessages, {
      ...config,
      metadata: {
        ...config.metadata,
        ...config.configurable.currentSkill,
      },
    });

    // ç²¾ç®€å“åº”äº‹ä»¶ï¼Œåªè®°å½•å“åº”é•¿åº¦åˆ°æ—¥å¿—
    const responseLength =
      typeof responseMessage.content === 'string'
        ? responseMessage.content.length
        : safeStringifyJSON(responseMessage.content).length;

    this.engine.logger.log(`Generated direct answer with ${responseLength} characters`);

    return {
      messages: [responseMessage],
      mcpActionResult: null,
    };
  }

  /**
   * Define the workflow for this skill
   * @returns The compiled runnable
   */
  toRunnable(): Runnable<GraphState, unknown> {
    // Create a simple linear workflow
    const workflow = new StateGraph<MCPAgentState>({
      channels: this.graphState,
    })
      .addNode('callMCPAgent', this.callMCPAgent.bind(this))
      .addEdge(START, 'callMCPAgent')
      .addEdge('callMCPAgent', END);

    return workflow.compile();
  }
}
