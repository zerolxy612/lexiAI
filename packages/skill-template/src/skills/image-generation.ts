import { START, END, StateGraphArgs, StateGraph } from '@langchain/langgraph';
import { z } from 'zod';
import { Runnable, RunnableConfig } from '@langchain/core/runnables';
import { BaseSkill, BaseSkillState, SkillRunnableConfig, baseStateGraphArgs } from '../base';
import { SystemMessage, AIMessage } from '@langchain/core/messages';
import {
  Icon,
  SkillInvocationConfig,
  SkillTemplateConfigDefinition,
  Artifact,
  InputMode,
  ArtifactType,
  CanvasNodeData,
  CanvasNodeType,
  CanvasNode,
} from '@refly/openapi-schema';
import { GraphState } from '../scheduler/types';
import { genImageID } from '@refly/utils';

// æ‰©å±•GraphStateæ¥å£ä»¥åŒ…å«gen_idå±æ€§
interface ImageGenerationState extends GraphState {
  gen_id?: string;
}

/**
 * Image Generation Skill
 *
 * Generates images based on text prompts using external API services
 */
export class ImageGeneration extends BaseSkill {
  name = 'imageGeneration';
  displayName = {
    en: 'Image Generation',
    'zh-CN': 'å›¾åƒç”Ÿæˆ',
  };

  icon: Icon = { type: 'emoji', value: 'ğŸ–¼ï¸' };

  configSchema: SkillTemplateConfigDefinition = {
    items: [
      {
        key: 'apiUrl',
        inputMode: 'input' as InputMode,
        defaultValue: 'https://api.tu-zi.com/v1/chat/completions',
        labelDict: {
          en: 'API URL',
          'zh-CN': 'API åœ°å€',
        },
        descriptionDict: {
          en: 'The API endpoint for image generation',
          'zh-CN': 'å›¾åƒç”ŸæˆAPIæ¥å£åœ°å€',
        },
      },
      {
        key: 'apiKey',
        inputMode: 'input' as InputMode,
        defaultValue: '',
        inputProps: {
          // @ts-ignore - ä½¿ç”¨å¯†ç ç±»å‹çš„è¾“å…¥æ¡†
          passwordType: true,
        },
        labelDict: {
          en: 'API Key',
          'zh-CN': 'API å¯†é’¥',
        },
        descriptionDict: {
          en: 'Your API key for the image generation service',
          'zh-CN': 'å›¾åƒç”ŸæˆæœåŠ¡çš„APIå¯†é’¥',
        },
      },
      {
        key: 'imageRatio',
        inputMode: 'select' as InputMode,
        defaultValue: '1:1',
        labelDict: {
          en: 'Image Ratio',
          'zh-CN': 'å›¾åƒæ¯”ä¾‹',
        },
        descriptionDict: {
          en: 'The aspect ratio of generated images',
          'zh-CN': 'ç”Ÿæˆå›¾åƒçš„å®½é«˜æ¯”',
        },
        options: [
          {
            value: '1:1',
            labelDict: { en: '1:1 (Square)', 'zh-CN': '1:1 (æ­£æ–¹å½¢)' },
          },
          {
            value: '16:9',
            labelDict: { en: '16:9 (Landscape)', 'zh-CN': '16:9 (æ¨ªå‘)' },
          },
          {
            value: '9:16',
            labelDict: { en: '9:16 (Portrait)', 'zh-CN': '9:16 (çºµå‘)' },
          },
        ],
      },
      {
        key: 'model',
        inputMode: 'select' as InputMode,
        defaultValue: 'gpt-4o-image-vip',
        labelDict: {
          en: 'Model',
          'zh-CN': 'æ¨¡å‹',
        },
        descriptionDict: {
          en: 'The model to use for image generation',
          'zh-CN': 'ç”¨äºå›¾åƒç”Ÿæˆçš„æ¨¡å‹',
        },
        options: [
          {
            value: 'gpt-4o-image-vip',
            labelDict: { en: 'GPT-4o-image-vip', 'zh-CN': 'GPT-4o-image-vip' },
          },
          {
            value: 'gpt-4o-image',
            labelDict: { en: 'GPT-4o-image', 'zh-CN': 'GPT-4o-image' },
          },
        ],
      },
    ],
  };

  invocationConfig: SkillInvocationConfig = {};

  description = 'æ ¹æ®æ–‡æœ¬æç¤ºä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆå›¾åƒ';

  schema = z.object({
    query: z.string().describe('The prompt for image generation'),
    gen_id: z.string().optional().describe('The ID of a previously generated image to edit'),
  });

  graphState: StateGraphArgs<BaseSkillState>['channels'] = {
    ...baseStateGraphArgs,
  };

  async generateImage(
    state: ImageGenerationState,
    config: SkillRunnableConfig,
  ): Promise<Partial<GraphState>> {
    const { query, gen_id } = state;
    const { tplConfig } = config.configurable;

    if (!query) {
      throw new Error('A prompt is required for image generation');
    }

    // Extract configuration values with defaults
    const apiUrl = tplConfig?.apiUrl?.value ?? 'https://api.tu-zi.com/v1/chat/completions';
    const apiKey = tplConfig?.apiKey?.value ?? '';
    const ratio = tplConfig?.imageRatio?.value ?? '1:1';
    const model = tplConfig?.model?.value ?? 'gpt-4o-image-vip';

    if (!apiKey) {
      throw new Error('API key is required for image generation');
    }

    config.metadata.step = { name: 'generateImage' };

    try {
      // Log the generation attempt
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'image.generating',
            titleArgs: {
              prompt: query,
            },
          },
        },
        config,
      );

      // Prepare the first message with proper JSON format
      const jsonConfig = {
        prompt: query,
        ratio: ratio,
      };

      // If gen_id is provided, add it to the JSON config for image editing
      const finalConfig = gen_id ? { ...jsonConfig, gen_id } : jsonConfig;

      // Create the message with proper formatting for the API
      const messages = [
        {
          role: 'user',
          content: `\`\`\`\n${JSON.stringify(finalConfig, null, 2)}\n\`\`\``,
        },
      ];

      // Add gen_id if provided for image editing
      const requestBody = {
        stream: true, // Use streaming for more responsive feedback
        model: model,
        messages: messages,
      };

      // Setup headers
      const headers = {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      };

      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'image.api.request',
            titleArgs: {
              url: apiUrl,
            },
          },
        },
        config,
      );

      // Make the API request
      const response = await fetch(apiUrl as string, {
        method: 'POST',
        headers: headers,
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorText = await response.text();
        // æ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        const errorMessage = `å›¾åƒç”Ÿæˆå¤±è´¥: ${response.status} - ${errorText}`;
        this.emitEvent(
          {
            event: 'log',
            log: {
              key: 'image.api.error',
              titleArgs: {
                status: response.status.toString(),
                error: errorText,
              },
            },
          },
          config,
        );
        throw new Error(errorMessage);
      }

      // Process the streaming response
      const reader = response.body?.getReader();
      if (!reader) {
        const errorMessage = 'æ— æ³•è¯»å–å“åº”æµ';
        this.emitEvent(
          {
            event: 'log',
            log: {
              key: 'image.stream.error',
              titleArgs: { error: errorMessage },
            },
          },
          config,
        );
        throw new Error(errorMessage);
      }

      let imageUrl = '';
      let genId = '';
      let fullResponse = '';

      // Stream reading logic with timeout
      const decoder = new TextDecoder();
      let done = false;

      // Set a timeout for reading the stream
      const timeout = 6000000; // 6000 seconds timeout
      const startTime = Date.now();

      // æ·»åŠ è¿›åº¦åé¦ˆ
      let progressReported = false;
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'image.stream.processing',
            titleArgs: { prompt: query },
          },
        },
        config,
      );

      while (!done && Date.now() - startTime < timeout) {
        const result = await reader.read();
        done = result.done;

        if (!done && result.value) {
          const chunk = decoder.decode(result.value, { stream: true });
          fullResponse += chunk;

          // æ¯15ç§’æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
          if (!progressReported && Date.now() - startTime > 15000) {
            progressReported = true;
            this.emitEvent(
              {
                event: 'log',
                log: {
                  key: 'image.stream.progress',
                  titleArgs: { seconds: Math.floor((Date.now() - startTime) / 1000).toString() },
                },
              },
              config,
            );
          }

          // Try to extract image URL and gen_id from accumulated response
          const urlMatch = fullResponse.match(/!\[.*?\]\((https:\/\/.*?)\)/);
          if (urlMatch?.[1] && !imageUrl) {
            imageUrl = urlMatch[1];
            console.log('Found image URL:', imageUrl);
            this.emitEvent(
              {
                event: 'log',
                log: {
                  key: 'image.url.found',
                  titleArgs: { url: imageUrl },
                },
              },
              config,
            );
          }

          const genIdMatch = fullResponse.match(/gen_id: `(.*?)`/);
          if (genIdMatch?.[1] && !genId) {
            genId = genIdMatch[1];
            console.log('Found gen_id:', genId);
            this.emitEvent(
              {
                event: 'log',
                log: {
                  key: 'image.genid.found',
                  titleArgs: { genId: genId },
                },
              },
              config,
            );
          }

          // If we have both URL and gen_id, we can stop reading
          if (imageUrl && genId) {
            break;
          }
        }
      }

      // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
      if (Date.now() - startTime >= timeout) {
        const errorMessage = 'å¤„ç†å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•';
        this.emitEvent(
          {
            event: 'log',
            log: {
              key: 'image.timeout',
              titleArgs: { timeout: (timeout / 1000).toString() },
            },
          },
          config,
        );
        throw new Error(errorMessage);
      }

      // If we couldn't find the image URL or gen_id in the response
      if (!imageUrl) {
        // å°è¯•ä½¿ç”¨å¤šç§æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        const alternativeUrlPatterns = [
          /!\[.*?\]\((https:\/\/.*?)\)/,
          /(https:\/\/.*?\.(?:png|jpg|jpeg|gif|webp))/i,
          /"url":\s*"(https:\/\/.*?)"/,
        ];

        for (const pattern of alternativeUrlPatterns) {
          const match = fullResponse.match(pattern);
          if (match?.[1]) {
            imageUrl = match[1];
            this.emitEvent(
              {
                event: 'log',
                log: {
                  key: 'image.url.found.alternative',
                  titleArgs: { url: imageUrl },
                },
              },
              config,
            );
            break;
          }
        }

        if (!imageUrl) {
          const errorMessage = 'æ— æ³•ä»å“åº”ä¸­æå–å›¾åƒURL';
          this.emitEvent(
            {
              event: 'log',
              log: {
                key: 'image.url.missing',
                titleArgs: { responseLength: fullResponse.length.toString() },
              },
            },
            config,
          );
          throw new Error(errorMessage);
        }
      }

      // Create artifact for the image
      const imageTitle = `ç”Ÿæˆå›¾åƒ: ${query.substring(0, 30)}${query.length > 30 ? '...' : ''}`;
      const imageId = genImageID();
      const storageKey = `${imageId}-${Date.now()}`;

      const artifact: Artifact = {
        entityId: imageId,
        type: 'document' as ArtifactType,
        title: imageTitle,
        content: '',
        status: 'finish',
        metadata: {
          url: imageUrl,
          prompt: query,
          gen_id: genId || 'unknown',
          model: model,
          ratio: ratio,
          mimeType: 'image/png',
        },
      };

      // Emit the artifact event which will be handled by the system
      this.emitEvent(
        {
          event: 'artifact',
          artifact,
        },
        config,
      );

      // é€šçŸ¥ç”¨æˆ·å›¾åƒæˆåŠŸåˆ›å»º
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'image.artifact.created',
            titleArgs: { title: imageTitle },
          },
        },
        config,
      );

      // å‡†å¤‡èŠ‚ç‚¹æ•°æ® - æŒ‰ç…§ImageNodeMetaçš„è¦æ±‚è®¾ç½®
      const nodeData: CanvasNodeData = {
        title: imageTitle,
        entityId: imageId,
        metadata: {
          imageUrl: imageUrl, // å¿…éœ€çš„å­—æ®µ
          imageType: 'png', // å¿…éœ€çš„å­—æ®µ
          storageKey: storageKey, // å¿…éœ€çš„å­—æ®µ
          showBorder: true,
          showTitle: true,
          sizeMode: 'adaptive',
          prompt: query,
          gen_id: genId || 'unknown',
          model: model,
          ratio: ratio,
          originalWidth: 400, // æ·»åŠ é»˜è®¤å®½åº¦
          style: {}, // æ·»åŠ ç©ºæ ·å¼å¯¹è±¡
        },
      };

      // åˆ›å»ºå®Œæ•´çš„CanvasèŠ‚ç‚¹
      const canvasNode: CanvasNode = {
        type: 'image' as CanvasNodeType,
        data: nodeData,
      };

      // è®°å½•å°è¯•åˆ›å»ºèŠ‚ç‚¹
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'image.node.creating',
            titleArgs: { entityId: imageId },
          },
        },
        config,
      );

      // Emit an event to create a new image node in the canvas
      this.emitEvent(
        {
          event: 'create_node',
          node: canvasNode,
        },
        config,
      );

      // è®°å½•èŠ‚ç‚¹åˆ›å»ºå·²å®Œæˆ
      this.emitEvent(
        {
          event: 'log',
          log: {
            key: 'image.node.created',
            titleArgs: { entityId: imageId },
          },
        },
        config,
      );

      // Create a special response message that includes the content needed for the AI message
      // This format ensures the image is displayed properly in the UI
      const aiMessageContent = [
        {
          type: 'image_url',
          image_url: {
            url: imageUrl,
            detail: 'high',
          },
        },
        {
          type: 'text',
          text: `\n\n**ç”Ÿæˆçš„å›¾åƒ**\n\næç¤ºè¯: ${query}\n\nå›¾åƒID: ${genId || 'unknown'}\n\næ³¨æ„: å¦‚æœå›¾åƒæœªæ˜¾ç¤ºåœ¨ç”»æ¿ä¸­ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–åˆ·æ–°é¡µé¢ã€‚å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨"å›¾åƒID"é‡æ–°ç”Ÿæˆã€‚`,
        },
      ];

      // Also create a plain system message as fallback
      const systemMessage = new SystemMessage(
        `![${imageTitle}](${imageUrl})\n\nç”Ÿæˆçš„å›¾åƒID: ${genId || 'unknown'}\n\næç¤ºè¯: ${query}\n\næ³¨æ„: å¦‚æœå›¾åƒæœªæ˜¾ç¤ºåœ¨ç”»æ¿ä¸­ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–åˆ·æ–°é¡µé¢ã€‚å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨"å›¾åƒID"é‡æ–°ç”Ÿæˆã€‚`,
      );

      // Try to create an AI message with multimodal content
      try {
        // Create an AI message with the image content
        const aiMessage = new AIMessage({
          content: aiMessageContent,
        });

        return { messages: [aiMessage] };
      } catch (error) {
        console.error('Error creating AI message with image:', error);
        // Fallback to system message if AI message creation fails
        return { messages: [systemMessage] };
      }
    } catch (error) {
      console.error('Image generation error:', error);

      // Handle errors
      this.emitEvent(
        {
          event: 'error',
          error: error.message || 'Unknown error during image generation',
        },
        config,
      );

      return {
        messages: [
          new SystemMessage(
            `å›¾åƒç”Ÿæˆé”™è¯¯: ${error.message}\n\nå¯èƒ½çš„è§£å†³æ–¹æ³•:\n1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ\n2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸\n3. ç®€åŒ–æç¤ºè¯\n4. æ£€æŸ¥APIæœåŠ¡æ˜¯å¦å¯ç”¨`,
          ),
        ],
      };
    }
  }

  toRunnable(): Runnable<any, any, RunnableConfig> {
    const workflow = new StateGraph<GraphState>({
      channels: this.graphState,
    })
      .addNode('generateImage', this.generateImage.bind(this))
      .addEdge(START, 'generateImage')
      .addEdge('generateImage', END);

    return workflow.compile();
  }
}
